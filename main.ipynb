{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets Read the document\n",
    "def read_doc(directory):\n",
    "    file_loader=PyPDFDirectoryLoader(directory)\n",
    "    documents=file_loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence vs. Human\n",
      "Intelligence: A Comprehensive Comparison\n",
      "Author Name\n",
      "June 19, 2025\n",
      "Abstract\n",
      "This article explores the multifaceted comparison between artificial intelligence\n",
      "(AI) and human intelligence, delving into cognitive abilities, collaboration, ethi-\n",
      "cal considerations, creativity, and future implications. By examining strengths,\n",
      "limitations, and synergies, we aim to provide a balanced perspective on how AI\n",
      "and humans can coexist and complement each other in an evolving technologi-\n",
      "cal landscape.\n",
      "Contents\n",
      "1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .3\n",
      "2 Cognitive Abilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .3\n",
      "2.1 Processing Speed and Accuracy. . . . . . . . . . . . . . . . . . . . . . . 3\n",
      "2.2 Memory and Recall . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n",
      "2.3 Learning and Adaptation. . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n",
      "2.4 Problem-Solving . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n",
      "3 Collaboration Between AI and Humans. . . . . . . . . . . . . . . . . . . 4\n",
      "3.1 AI as a Tool . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n",
      "3.2 Human Oversight . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n",
      "3.3 Creative Partnerships . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n",
      "4 Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5\n",
      "4.1 Bias in AI Systems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n",
      "4.2 Accountability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n",
      "4.3 Job Displacement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n",
      "5 Creativity and Emotional Intelligence . . . . . . . . . . . . . . . . . . . . 5\n",
      "5.1 AI-Generated Art . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n",
      "5.2 Emotional Understanding . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n",
      "5.3 Innovation and Originality. . . . . . . . . . . . . . . . . . . . . . . . . . 6\n",
      "1\n",
      "{'producer': 'xdvipdfmx (20220710)', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-06-19T13:48:20+00:00', 'source': 'documents\\\\ai_vs_human.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "doc=read_doc('documents/')\n",
    "len(doc)\n",
    "first_doc = doc[0]  \n",
    "print(first_doc.page_content)  \n",
    "print(first_doc.metadata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 118\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunked_docs = text_splitter.split_documents(doc)\n",
    "print(f\"Number of chunks: {len(chunked_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafin\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors=embeddings.embed_query(\"How are you?\")\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"PINECONE_API_KEY not found in .env file\")\n",
    "\n",
    "pc = Pinecone(api_key=api_key)\n",
    "index_name = \"ragapp\"\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed chunked documents\n",
    "texts = [doc.page_content for doc in chunked_docs]\n",
    "vectors = embeddings.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 118}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for upsert\n",
    "data = [\n",
    "    (\n",
    "        str(i),                    # Unique ID for each vector\n",
    "        vectors[i],                # Embedding vector\n",
    "        {\"text\": texts[i], **chunked_docs[i].metadata}  # Metadata (text and original metadata)\n",
    "    )\n",
    "    for i in range(len(vectors))\n",
    "]\n",
    "\n",
    "# Upsert to Pinecone\n",
    "index.upsert(vectors=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index stats: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 118}},\n",
      " 'total_vector_count': 118,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Verify upsert\n",
    "stats = index.describe_index_stats()\n",
    "print(f\"Index stats: {stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pinecone_similarity_search(query, k=2):\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    response = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafin\\AppData\\Local\\Temp\\ipykernel_11240\\1542718995.py:7: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
      "  chain=load_qa_chain(llm,chain_type=\"stuff\")\n"
     ]
    }
   ],
   "source": [
    "api_key_groq = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(\n",
    "    api_key=api_key_groq, \n",
    "    model=\"allam-2-7b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain=load_qa_chain(llm,chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone vector store for langchain\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings, pinecone_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up RetrievalQA chain\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search answers\n",
    "def retrieve_answers(query):\n",
    "    if not query or not isinstance(query, str):\n",
    "        raise ValueError(\"Query must be a non-empty string\")\n",
    "    try:\n",
    "        response = qa_chain.run(query)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to retrieve answer: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafin\\AppData\\Local\\Temp\\ipykernel_11240\\3402383252.py:6: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the provided information, the main topics of the documents seem to be:\n",
      "\n",
      "1. 8.2 Case Study: AI in Journalism\n",
      "2. 8.3 Case Study: Autonomous Surgery\n",
      "3. 9 Challenges in Integration\n",
      "4. 9.1 Technical Limitations\n",
      "5. 9.2 Cultural Resistance\n",
      "\n",
      "These topics are discussed in the context and appear to be related to the integration of artificial intelligence (AI) and its challenges in various fields such as journalism, surgery, and cultural resistance. However, the specific document you are referring to is not mentioned, so I cannot determine its main topic without further information. \n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "query = \"What is the main topic of the documents?\"\n",
    "answer = retrieve_answers(query)\n",
    "print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
